{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cd19f2ba",
   "metadata": {
    "id": "cd19f2ba"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random, os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from resnet20_cifar import resnet20\n",
    "import thop\n",
    "from thop import profile, clever_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025235f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, you can proceed to use it\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available. Using GPU.')\n",
    "else:\n",
    "    # CUDA is not available, use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55865fea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55865fea",
    "outputId": "442559cb-d299-4cfe-c0f3-7c6f5f8e9b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# ----------------- prepare training data -----------------------\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data.cifar10',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# ----------------- prepare testing data -----------------------\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data.cifar10/',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "85f7f787",
   "metadata": {
    "id": "85f7f787"
   },
   "outputs": [],
   "source": [
    "# Make DataLoaders for the training and test data, with a batch size of 64\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ffaa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9dde37f",
   "metadata": {
    "id": "c9dde37f"
   },
   "outputs": [],
   "source": [
    "class_dict = {0: \"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90dfe034",
   "metadata": {
    "id": "90dfe034"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967279cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seeding for the training process\n",
    "seed = 1000\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6e5d9dd",
   "metadata": {
    "id": "f6e5d9dd"
   },
   "outputs": [],
   "source": [
    "class Convolutional_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super (Convolutional_CIFAR, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(512 * 3 * 3, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 200)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        self.out = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        leaky_relu = nn.LeakyReLU(negative_slope=0.1)\n",
    "        x = leaky_relu(self.conv1(x))\n",
    "        x = self.pool(leaky_relu(self.conv2(x)))\n",
    "        x = leaky_relu(self.conv3(x))\n",
    "        x = leaky_relu(self.conv4(x))\n",
    "        x = self.pool(leaky_relu(self.conv5(x)))\n",
    "        x = x.view(-1, 512 * 3 * 3)\n",
    "        x = leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x = leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e965db9e",
   "metadata": {
    "id": "e965db9e"
   },
   "outputs": [],
   "source": [
    "def train(save_dir = \"model\",\n",
    "         model_name = \"convolutional-cifar\"):\n",
    "    \n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    \n",
    "    model = Convolutional_CIFAR()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    # If there is no save directory yet, make one\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for step, (input, labels) in enumerate(train_loader):\n",
    "            model.train()   # set the model in training mode\n",
    "\n",
    "            input = input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input)\n",
    "\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Every 50 steps, calculate training accuracy, test the model, and print updated results\n",
    "            if step % 50 == 0:\n",
    "                # Progress update\n",
    "                train_acc, accuracy = progress_update(outputs=outputs, labels=labels,\n",
    "                                                      train_correct=train_correct,\n",
    "                                                      train_total=train_total,\n",
    "                                                      train_loss=train_loss,\n",
    "                                                      model=model, test_loader=test_loader,\n",
    "                                                      loss_func=loss_func, epoch=epoch, step=step)\n",
    "\n",
    "                # Save the model\n",
    "                save_model(model, model_name, accuracy)\n",
    "                \n",
    "            # Track training and test accuracies at the end of each epoch (step=750)\n",
    "            if step == 750:\n",
    "                train_list.append(train_acc)\n",
    "                test_list.append(accuracy)\n",
    "                \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27a2054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_update(outputs=None, labels=None, train_correct=None, train_total=None,\n",
    "                    train_loss=None, model=None, test_loader=None, loss_func=None, epoch=None, step=None):\n",
    "    # Take model's predictions on training set\n",
    "    # Calculate its accuracy on training set\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    train_total += labels.size(0)\n",
    "    train_correct += (predicted == labels).sum()\n",
    "    train_acc = (100 * (train_correct/train_total))\n",
    "    train_acc = train_acc.item()\n",
    "\n",
    "    # Now test the model on the test set, get the test accuracy and test loss\n",
    "    accuracy, test_loss = test(model=model, test_loader=test_loader, loss_func=loss_func)\n",
    "\n",
    "    # Show the results\n",
    "    print('Epoch[{}]:Step[{}] Train Loss: {:.2f}\\tTrain Acc: {:.2f}%\\tTest Loss: {:.2f}\\t\\tTest Acc: {:.2f}%'.format(\n",
    "    epoch, step, train_loss, train_acc, test_loss, accuracy))\n",
    "    \n",
    "    return train_acc, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9311cce6",
   "metadata": {
    "id": "9311cce6"
   },
   "outputs": [],
   "source": [
    "def test(model=None, test_image=None, test_loader=None, loss_func=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if model is None:\n",
    "        model = load_model()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Transform the image to match the format expected by the model\n",
    "    # This is primarily for single image inferences\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # If a test_loader is not provided, create a DataLoader to test a single image\n",
    "    if test_loader is None:\n",
    "        try:\n",
    "            inference(test_image=test_image, model=model, transform=transform)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print()\n",
    "            print(\"Pass in an image to be classified!\")\n",
    "            print(\"If you already did, but are still getting an error, make sure you have trained the model already\")\n",
    "            print(\"Call 'python classify.py train' from the command line first, let it train, then test your image\")\n",
    "            print()\n",
    "    # If a test_loader IS provided, i.e. every 50 steps during the training loop, execute the code below\n",
    "    else:\n",
    "        try:\n",
    "            accuracy, test_loss = evaluate(model=model, test_loader=test_loader,\n",
    "                                                    loss_func=loss_func, correct=correct, total=total)\n",
    "            return accuracy, test_loss\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print()\n",
    "            print(\"If you are here, I have no idea how\")\n",
    "            print(\"You might not have a model trained and saved to your present working directory\")\n",
    "            print(\"Call the train method on this classifier to train and save a model, then test it\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fbe4284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_image=None, model=None, transform=None):\n",
    "    # Load the test image and apply transformations\n",
    "    test_image = Image.open(test_image).convert('RGB')\n",
    "    test_image = transform(test_image).unsqueeze(0)\n",
    "    test_image = test_image.to(device)\n",
    "\n",
    "    model.eval()  # switch the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        def hook_fn(module, input, output):\n",
    "            global activation\n",
    "            activation = output\n",
    "\n",
    "        # Attach the hook to the first convolutional layer\n",
    "        first_conv_layer = model.conv1\n",
    "        hook = first_conv_layer.register_forward_hook(hook_fn)\n",
    "                \n",
    "        output = model(test_image)\n",
    "        label_value, label_index = torch.max(output, 1)\n",
    "        answer = class_dict[label_index.item()]\n",
    "        print(\"This is an image of a(n): \", answer)\n",
    "\n",
    "        hook.remove()\n",
    "                \n",
    "        # Check if activation was captured\n",
    "        if activation is not None:\n",
    "            # Access the first layer activation (feature maps)\n",
    "            feature_maps = activation[0]\n",
    "            num_filters = feature_maps.size(0)\n",
    "            # Visualize the feature maps\n",
    "            fig, axarr = plt.subplots(4, 8)  # Assuming 32 filters, adjust as needed\n",
    "            for i in range(num_filters):\n",
    "                ax = axarr[i // 8, i % 8]\n",
    "                ax.imshow(feature_maps[i].cpu(), cmap='viridis')\n",
    "                ax.axis('off')\n",
    "            plt.show()\n",
    "            plt.savefig('CONV_rslt.png')\n",
    "        else:\n",
    "            print(\"No activation captured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a98dd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model=None, test_loader=None, loss_func=None, correct=None, total=None):\n",
    "    model.eval()  # switch the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            test_loss = loss_func(outputs, labels)\n",
    "\n",
    "            # Increment total number of observations seen by\n",
    "            # number of items in this batch\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Increment total number of correct predictions by\n",
    "            # number of correct predictions in this batch\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "        accuracy = (100 * (correct/total))\n",
    "        accuracy = accuracy.item()\n",
    "        return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "adb5fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetDataWithTransform(Dataset):\n",
    "    def __init__(self, original_dataset, transform=None):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, label = self.original_dataset[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2af2b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_resnet20():\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "                \n",
    "    transformed_resnet_dataset = ResnetDataWithTransform(test_data, transform=resnet_transform)\n",
    "    \n",
    "    # Create a new DataLoader with the transformed dataset\n",
    "    resnet_test_loader = Data.DataLoader(transformed_resnet_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = resnet20()\n",
    "    model_path = \"./resnet20_cifar10_pretrained.pt\"\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    accuracy, test_loss = test(model=model, test_loader=resnet_test_loader, loss_func=loss_func)\n",
    "    print(\"ResNet20 Test Loss: {:.2f}\\tResNet20 Test Accuracy: {:.2f}\".format(test_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4240940c",
   "metadata": {
    "id": "4240940c"
   },
   "outputs": [],
   "source": [
    "def save_highest_accuracy(accuracy):\n",
    "    with open(\"highest_accuracy.txt\", \"w\") as f:\n",
    "        f.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9065c009",
   "metadata": {
    "id": "9065c009"
   },
   "outputs": [],
   "source": [
    "def load_highest_accuracy():\n",
    "    if os.path.exists(\"highest_accuracy.txt\"):\n",
    "        with open(\"highest_accuracy.txt\", \"r\") as f:\n",
    "            return float(f.read())\n",
    "    else:\n",
    "        return 0.0  # Default to 0.0 if the file doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c56d3d1a",
   "metadata": {
    "id": "c56d3d1a"
   },
   "outputs": [],
   "source": [
    "def save_model(model, model_name, accuracy):\n",
    "\n",
    "    highest_accuracy = load_highest_accuracy()\n",
    "\n",
    "    # Only save the model if its accuracy is higher than the previous model's\n",
    "    if accuracy > highest_accuracy:\n",
    "\n",
    "        save_highest_accuracy(accuracy)\n",
    "\n",
    "        file_path = \"./model/{}.pt\".format(model_name)\n",
    "\n",
    "        print(\"New highest accuracy. Saving model ...\")\n",
    "        print()\n",
    "\n",
    "        torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "02d91c2a",
   "metadata": {
    "id": "02d91c2a"
   },
   "outputs": [],
   "source": [
    "def load_model(model=None, device=\"cuda\"):\n",
    "\n",
    "    if model is None:\n",
    "        model = Convolutional_CIFAR()\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(\"./model/convolutional-cifar.pt\"))\n",
    "        device = torch.device(device)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4024abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Convolutional_CIFAR()\n",
    "\n",
    "# # Create a sample input tensor\n",
    "# input_tensor = torch.randn(1, 3, 32, 32)  \n",
    "\n",
    "# # Profile the model to count MACs\n",
    "# macs, params = profile(model, inputs=(input_tensor,))\n",
    "# macs, params = clever_format([macs, params], \"%.3f\")\n",
    "# print(f\"MACs: {macs}, Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b3fb4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_model = resnet20()\n",
    "# res_model_path = \"./resnet20_cifar10_pretrained.pt\"\n",
    "# res_model.load_state_dict(torch.load(res_model_path)) \n",
    "\n",
    "# # Profile the model to count MACs\n",
    "# macs, params = profile(res_model, inputs=(input_tensor,))\n",
    "# macs, params = clever_format([macs, params], \"%.3f\")\n",
    "# print(f\"MACs: {macs}, Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9ca03f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 10\n",
    "# image = test_data[i][0]\n",
    "# print(test_data[i][1])\n",
    "\n",
    "# plt.imshow(transforms.ToPILImage()(image))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9c2d8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(test_image=\"/home/jts75596/deep_learning/HW2/plane.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9063fd19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9063fd19",
    "outputId": "698e80d6-4670-4919-d9c9-849e3041b8c3"
   },
   "outputs": [],
   "source": [
    "# train_list = []\n",
    "# test_list = []\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f080c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2c4fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(epoch_list, train_list, label=\"Training Accuracy\", color=\"blue\")\n",
    "# plt.plot(epoch_list, test_list, label=\"Testing Accuracy\", color=\"orange\")\n",
    "\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Accuracies At the End of Each Epoch\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45737a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd775764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest_acc_list = [80.21, 80.63, 80.72]\n",
    "# print(\"Mean accuracy: \", np.mean(highest_acc_list))\n",
    "# print(\"Standard deviation: \", np.std(highest_acc_list))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
